# -*- coding: utf-8 -*-
"""StrokePrediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_gGRC4q0ofu4VGbPnBFXlPhiDLUn-cQt
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

path="/content/drive/MyDrive/healthcare-dataset-stroke-data.csv"
df=pd.read_csv(path)

df.head()

df.info()

df.isnull().sum()

df.corr()["stroke"].sort_values()[:-1]

sns.pairplot(data=df)

correlation_matrix = df.apply(lambda x: x.factorize()[0]).corr(method='pearson')
plt.figure(figsize=(11,9))
sns.heatmap(correlation_matrix, annot = True)
plt.show()

df.bmi.fillna(28.8,axis=0,inplace=True)

df.head()

import plotly.express as px

gecici_data = df['smoking_status'].value_counts().rename_axis('Smoking-Status').reset_index(name='Counts in each category of smoking status')
gecici_data

import plotly.express as px
fig = px.bar(gecici_data,x='Smoking-Status',y='Counts in each category of smoking status',title='Category of people in smoking',hover_data=['Smoking-Status', 'Counts in each category of smoking status'], color='Smoking-Status',width=700,height=700)
fig.update_xaxes(type='category')
fig.show()

fig = px.pie(df, values='avg_glucose_level', names='gender',title='Average level of glucose in Males and Females',width=800,color_discrete_sequence=px.colors.sequential.RdBu)
fig.show()

fig = px.pie(df, values='avg_glucose_level', names='Residence_type', title='Average level of glucose residence wise',width=700)
fig.show()

gecici_data = df['work_type'].value_counts().rename_axis('Type of Work').reset_index(name='Number of people working in each category')
gecici_data

fig = px.bar(gecici_data,x='Type of Work',y='Number of people working in each category',title='Number of people in working category',hover_data=['Type of Work', 'Number of people working in each category'], color='Type of Work',width=900,height=700)
fig.update_xaxes(type='category')
fig.show()

gecici_df = df.filter(['gender','heart_disease','hypertension'])
gecici_df

gecici_df = gecici_df.groupby('gender').count().reset_index()
gecici_df

df

df.drop(columns=['id'],inplace=True)
df

def create_contingency_table(dataframe):
    table=[]
    for i in range(len(dataframe)):
        col = []
        for j in range(len(dataframe.columns)):
            col.append(dataframe[dataframe.columns[j]][i])
        table.append(col)
    return table


def chi_square_test(table):

    from scipy.stats import chi2_contingency
    from scipy.stats import chi2
    stat, p, dof, expected = chi2_contingency(table)
    print('Degree of freedom: ', dof)
    print('Stat is: ', stat)
    print('P-value is: ',p)
    print('Expected frquencies: ',expected)
    
    # interpret test-statistic
    prob = 0.95
    critical = chi2.ppf(prob, dof)
    print('Critical value=%.3f, Stat=%.3f' % (critical, stat))
    if abs(stat) >= critical:
        print('Dependent (reject H0)')
    else:
        print('Independent (fail to reject H0)')
    
    # interpret p-value
    alpha = 1.0 - prob
    print('significance=%.3f, p=%.3f' % (alpha, p))
    if p <= alpha:
        print('Dependent (reject H0)')
    else:
        print('Independent (fail to reject H0)')

data_gender_married = pd.crosstab(df['gender'],df['ever_married'])
print(data_gender_married)
table = create_contingency_table(data_gender_married)
print(table)
chi_square_test(table)

dummies_gender = pd.get_dummies(df['gender'])
dummies_work_type = pd.get_dummies(df['work_type'])
dummies_residence_type = pd.get_dummies(df['Residence_type'])
dummies_smoking_status = pd.get_dummies(df['smoking_status'])

final_df = pd.concat([df,dummies_gender,dummies_work_type,dummies_residence_type,dummies_smoking_status],axis='columns')
final_df

final_df.drop(columns=['gender','ever_married','work_type','Residence_type','smoking_status'],inplace=True)
final_df

y = final_df['stroke']
X = final_df.drop(columns=['stroke'])

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4,random_state=42)



from sklearn.linear_model import LogisticRegression as lr
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler

pipe = make_pipeline(StandardScaler(), lr())
pipe.fit(X_train,y_train)

print("Model Accuracy on Testing Data: ", pipe.score(X_test,y_test))

from sklearn.metrics import confusion_matrix
y_pred = pipe.predict(X_test)
confusion_matrix(y_test,y_pred)

from sklearn.metrics import classification_report
target_names = ['Person does not have chances of stroke', 'Person has chances of stroke']
print(classification_report(y_test, y_pred, target_names=target_names))